# LiteLLM Context Engineering Environment Configuration for ERNI-KI
# Copy to env/litellm.env and set values
# Updated: 2025-09-19 | Status: Production Ready (Context7 integration enabled)
# Capabilities: Unified API for LLM providers + Context Engineering

# === Core settings ===
# Master key for LiteLLM admin (must start with sk-)
LITELLM_MASTER_KEY=sk-CHANGE_THIS_MASTER_KEY_BEFORE_PRODUCTION

# Salt key for encrypting API keys (DO NOT CHANGE after first run)
# Generate via: openssl rand -hex 32
LITELLM_SALT_KEY=CHANGE_THIS_SALT_KEY_64_CHARS_LONG_NEVER_CHANGE_AFTER_FIRST_RUN

# === DATABASE INTEGRATION ===
# PostgreSQL connection for metadata storage
# ⚠️ Password must match POSTGRES_PASSWORD in db.env
DATABASE_URL=postgresql://postgres:CHANGE_THIS_PASSWORD_BEFORE_PRODUCTION@db:5432/openwebui

# Enable model storage in DB
STORE_MODEL_IN_DB=True

# Database schema for LiteLLM isolation
DATABASE_SCHEMA=litellm

# === REDIS INTEGRATION ===
# Redis for caching and rate limiting
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=1

# === OLLAMA INTEGRATION ===
# Ollama API base URL for local LLM
OLLAMA_API_BASE=http://ollama:11434

# === EXTERNAL LLM PROVIDERS ===
# OpenAI API (optional)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic Claude API (optional)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google Gemini API (optional)
GOOGLE_API_KEY=your-google-api-key-here

# === SECURITY SETTINGS ===
# Disable spend logging for security
LITELLM_LOG_LEVEL=INFO
DISABLE_SPEND_LOGS=True

# Max budget in USD
MAX_BUDGET=1000

# Enable audit logs
ENABLE_AUDIT_LOGS=True

# === PERFORMANCE SETTINGS ===
# Worker process count
NUM_WORKERS=4

# Batch size for DB writes
PROXY_BATCH_WRITE_AT=100

# Timeout settings (seconds)
REQUEST_TIMEOUT=600
CONNECT_TIMEOUT=10

# === MONITORING & HEALTH ===
# Enable health checks
ENABLE_HEALTH_CHECKS=True

# Prometheus metrics endpoint
ENABLE_PROMETHEUS_METRICS=True
PROMETHEUS_PORT=9090

# === CONTEXT ENGINEERING SETTINGS ===
# Enable intelligent routing
ENABLE_INTELLIGENT_ROUTING=True

# Routing strategy (cost-based, latency-based, usage-based-routing-v2)
ROUTING_STRATEGY=usage-based-routing-v2

# Enable pre-call checks
ENABLE_PRE_CALL_CHECK=True

# Fallback model if primary unavailable
FALLBACK_MODEL=ollama/llama3.2:3b

# === RATE LIMITING ===
# Global rate limits (requests per minute)
GLOBAL_RPM_LIMIT=1000
GLOBAL_TPM_LIMIT=100000

# Per-user rate limits
USER_RPM_LIMIT=60
USER_TPM_LIMIT=10000

# === CACHING SETTINGS ===
# Enable response caching
ENABLE_CACHING=True

# Cache TTL (seconds)
CACHE_TTL=3600

# Cache type (redis, memory)
CACHE_TYPE=redis

# === LOGGING CONFIGURATION ===
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log format (json, text)
LOG_FORMAT=json

# Disable verbose logging for production
LITELLM_LOG=INFO

# === INTEGRATION SETTINGS ===
# OpenWebUI integration
OPENWEBUI_BASE_URL=http://openwebui:8080

# Auth server integration
AUTH_SERVER_URL=http://auth:9090

# === BACKUP & RECOVERY ===
# Backup config to S3/GCS (optional)
# LITELLM_CONFIG_BUCKET_TYPE=s3
# LITELLM_CONFIG_BUCKET_NAME=erni-ki-backups
# LITELLM_CONFIG_BUCKET_OBJECT_KEY=litellm/config.yaml

# === DEVELOPMENT SETTINGS ===
# Enable for development only
# DETAILED_DEBUG=False
# DROP_PARAMS=True

# === CUSTOM HEADERS ===
# Add custom headers to all requests
CUSTOM_HEADERS='{"X-ERNI-KI-Version": "1.0", "X-Service": "LiteLLM"}'

# === WEBHOOK NOTIFICATIONS ===
# Webhook URL for event notifications
# WEBHOOK_URL=https://your-webhook-endpoint.com/litellm

# === SSL/TLS SETTINGS ===
# SSL settings for production (if needed)
# SSL_KEYFILE_PATH=/app/ssl/keyfile.key
# SSL_CERTFILE_PATH=/app/ssl/certfile.crt

# === ENVIRONMENT ===
# Environment type
ENV=production

# Service name for logging
SERVICE_NAME=litellm-erni-ki

# Version for monitoring
SERVICE_VERSION=main-stable

# === CONTEXT7 INTEGRATION ===
# Context Engineering for improved AI context
# Context7 API key (get at https://context7.com)
CONTEXT7_API_KEY=CHANGE_THIS_CONTEXT7_API_KEY_BEFORE_PRODUCTION
CONTEXT7_ENABLED=true
CONTEXT7_ENHANCEMENT_LEVEL=advanced
CONTEXT7_INCLUDE_EXAMPLES=true

# === Monitoring integration ===
# Settings for ERNI-KI monitoring stack (18 Grafana dashboards)
PROMETHEUS_METRICS_ENABLED=true
GRAFANA_DASHBOARD_INTEGRATION=true
MONITORING_SYSTEM_VERSION=2025-09-19

# === IMPORTANT: CHANGE BEFORE PRODUCTION ===
# ⚠️ Replace CHANGE_THIS_MASTER_KEY_BEFORE_PRODUCTION with a unique master key
# ⚠️ Replace CHANGE_THIS_SALT_KEY_64_CHARS_LONG_NEVER_CHANGE_AFTER_FIRST_RUN with a 64-char salt key
# ⚠️ Replace CHANGE_THIS_PASSWORD_BEFORE_PRODUCTION with real PostgreSQL password
# ⚠️ Replace CHANGE_THIS_CONTEXT7_API_KEY_BEFORE_PRODUCTION with your Context7 API key
# ⚠️ Set OLLAMA_BASE_URL to your Ollama config
# ⚠️ Verify all external API providers are reachable
# ⚠️ Ensure Context7 integration works
