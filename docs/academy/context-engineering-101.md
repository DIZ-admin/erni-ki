---
language: ru
translation_status: draft
doc_version: '2025.11'
last_updated: '2025-12-01'
---

# Context Engineering 101

> Коротко: контекст-инжиниринг = как подать модели правильные данные, историю и
> инструменты в нужный момент, чтобы ответы были точными, быстрыми и
> безопасными.

## Что это и зачем

- Контекст — не только промпт. Это системные инструкции, извлечённые документы
  (RAG/Context7/Docling), история диалога, результаты инструментов (LiteLLM
  tools), ограничения по безопасности.
- Цель: минимальный, но достаточный набор токенов, чтобы модель опиралась на
  проверенные источники (Redis/RAG) и не фантазировала.

## Анатомия контекста в ERNI-KI

- **System prompt:** роль, политики, запреты.
- **Retrieved docs:** релевантные фрагменты (Context7, Docling, Tika).
- **User history:** последние сообщения/решения (усекать по важности, не по
  длине).
- **Tool outputs:** результаты API/скриптов, которые должны попасть в итоговый
  ответ.
- **Guardrails:** фильтры, лимиты токенов, приватность (не добавлять личные
  данные без явного разрешения).

## Практика: как готовить контекст

- **Отбор источников:** только доверенные коллекции; помечайте версии и даты.
- **Обрезка:** удаляйте шум (приветствия, дубликаты), оставляйте маркеры
  разделов и заголовки.
- **Сжатие:** делайте краткие выжимки, если фрагменты слишком длинные, но не
  убирайте цифры и ключевые факты.
- **Границы приватности:** не подмешивайте персональные данные/внутренние ссылки
  без разрешения; используйте redaction, если сомневаетесь.
- **Проверка полноты:** перед отправкой убедитесь, что в контексте есть ответ на
  вопрос пользователя; если нет — запросите недостающие данные.

## Чек-лист для разработчиков (RAG/агенты)

- Определите бюджет токенов: сколько под систему, сколько под retrieved docs,
  сколько под историю.
- Ранжируйте документы: BM25 + векторный поиск + rerank → топ-k → усечение.
- Логируйте, что именно ушло в контекст: это база для дебага и снижения
  стоимости.
- Добавляйте source tags в контекст, чтобы модель могла ссылаться на источники.
- Если ответ не найден в контексте — возвращайте "нет данных" вместо догадок.

## Когда дело не в контексте

- Нужна новая функция → меняйте пайплайн/модель, а не раздувайте контекст.
- Узкие ограничения (PII, лицензии) → применяйте фильтры до и после модели.
- Сложные вычисления → отдавайте инструментам, а не LLM.

## Связанные материалы

- Prompting 101: базовые паттерны и лимиты промптов.
- RAG и мониторинг: разделы Operations → Monitoring (Redis/LiteLLM/Context7).
