#!/bin/bash
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU –¥–ª—è ERNI-KI
# –ê–≤—Ç–æ—Ä: –ê–ª—å—Ç—ç–æ–Ω –®—É–ª—å—Ü (Tech Lead)

set -e

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# –§—É–Ω–∫—Ü–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log() { echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"; }
success() { echo -e "${GREEN}‚úÖ $1${NC}"; }
warning() { echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"; }
error() { echo -e "${RED}‚ùå $1${NC}"; }
info() { echo -e "${CYAN}‚ÑπÔ∏è  $1${NC}"; }
section() { echo -e "${PURPLE}üîç $1${NC}"; }

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
check_gpu_availability() {
    section "–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU"
    
    if command -v nvidia-smi &> /dev/null; then
        success "nvidia-smi –¥–æ—Å—Ç—É–ø–µ–Ω"
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
        local gpu_info=$(nvidia-smi --query-gpu=name,driver_version,memory.total,compute_cap --format=csv,noheader,nounits)
        local gpu_name=$(echo "$gpu_info" | cut -d, -f1 | tr -d ' ')
        local driver_version=$(echo "$gpu_info" | cut -d, -f2 | tr -d ' ')
        local memory_total=$(echo "$gpu_info" | cut -d, -f3 | tr -d ' ')
        local compute_cap=$(echo "$gpu_info" | cut -d, -f4 | tr -d ' ')
        
        success "GPU: $gpu_name"
        success "–î—Ä–∞–π–≤–µ—Ä: $driver_version"
        success "–ü–∞–º—è—Ç—å: ${memory_total} MB"
        success "Compute Capability: $compute_cap"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
        local temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
        local power=$(nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits)
        local power_limit=$(nvidia-smi --query-gpu=power.limit --format=csv,noheader,nounits)
        
        success "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: ${temp}¬∞C"
        success "–≠–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: ${power}W / ${power_limit}W"
        
    else
        error "nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        return 1
    fi
    echo ""
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ Docker
check_gpu_in_docker() {
    section "–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama
    log "–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ Ollama..."
    local ollama_logs=$(docker-compose logs ollama 2>/dev/null | grep -i gpu | tail -3)
    if [[ "$ollama_logs" == *"cuda"* ]]; then
        success "Ollama –∏—Å–ø–æ–ª—å–∑—É–µ—Ç CUDA"
        echo "$ollama_logs" | while read line; do
            info "  $line"
        done
    else
        warning "Ollama –º–æ–∂–µ—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU"
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ GPU
    log "–ü—Ä–æ—Ü–µ—Å—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ GPU:"
    nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv,noheader | while read line; do
        if [[ "$line" == *"ollama"* ]]; then
            success "  $line"
        else
            info "  $line"
        fi
    done
    
    echo ""
}

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
test_generation_performance() {
    section "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama API
    if ! curl -sf http://localhost:11434/api/version &> /dev/null; then
        error "Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        return 1
    fi
    
    success "Ollama API –¥–æ—Å—Ç—É–ø–µ–Ω"
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
    local models=$(curl -s http://localhost:11434/api/tags | jq -r '.models[].name' 2>/dev/null || echo "")
    if [ -z "$models" ]; then
        warning "–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        return 1
    fi
    
    local test_model=$(echo "$models" | head -1)
    success "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–æ–¥–µ–ª—å—é: $test_model"
    
    # –¢–µ—Å—Ç 1: –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç
    log "–¢–µ—Å—Ç 1: –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç"
    local short_prompt="–ü—Ä–∏–≤–µ—Ç!"
    local start_time=$(date +%s.%N)
    
    local response1=$(curl -s -X POST http://localhost:11434/api/generate \
        -H "Content-Type: application/json" \
        -d "{\"model\":\"$test_model\",\"prompt\":\"$short_prompt\",\"stream\":false}")
    
    local end_time=$(date +%s.%N)
    local time1=$(echo "scale=3; $end_time - $start_time" | bc)
    
    if [[ "$response1" == *"response"* ]]; then
        success "–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–∫–æ—Ä–æ—Ç–∫–∏–π): ${time1}s"
        local tokens1=$(echo "$response1" | jq -r '.eval_count // 0')
        if [ "$tokens1" -gt 0 ]; then
            local tokens_per_sec1=$(echo "scale=1; $tokens1 / $time1" | bc)
            success "–°–∫–æ—Ä–æ—Å—Ç—å: ${tokens_per_sec1} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫"
        fi
    else
        error "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"
    fi
    
    # –¢–µ—Å—Ç 2: –î–ª–∏–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    log "–¢–µ—Å—Ç 2: –î–ª–∏–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç"
    local long_prompt="–†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–æ –æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –û–±—ä—è—Å–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏."
    local start_time2=$(date +%s.%N)
    
    local response2=$(curl -s -X POST http://localhost:11434/api/generate \
        -H "Content-Type: application/json" \
        -d "{\"model\":\"$test_model\",\"prompt\":\"$long_prompt\",\"stream\":false}")
    
    local end_time2=$(date +%s.%N)
    local time2=$(echo "scale=3; $end_time2 - $start_time2" | bc)
    
    if [[ "$response2" == *"response"* ]]; then
        success "–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–¥–ª–∏–Ω–Ω—ã–π): ${time2}s"
        local tokens2=$(echo "$response2" | jq -r '.eval_count // 0')
        if [ "$tokens2" -gt 0 ]; then
            local tokens_per_sec2=$(echo "scale=1; $tokens2 / $time2" | bc)
            success "–°–∫–æ—Ä–æ—Å—Ç—å: ${tokens_per_sec2} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫"
        fi
    else
        error "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"
    fi
    
    # –¢–µ—Å—Ç 3: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    log "–¢–µ—Å—Ç 3: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (3 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)"
    local parallel_start=$(date +%s.%N)
    
    for i in {1..3}; do
        {
            local req_start=$(date +%s.%N)
            local req_response=$(curl -s -X POST http://localhost:11434/api/generate \
                -H "Content-Type: application/json" \
                -d "{\"model\":\"$test_model\",\"prompt\":\"–¢–µ—Å—Ç $i: –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç\",\"stream\":false}")
            local req_end=$(date +%s.%N)
            local req_time=$(echo "scale=3; $req_end - $req_start" | bc)
            
            if [[ "$req_response" == *"response"* ]]; then
                echo "–ó–∞–ø—Ä–æ—Å $i: ${req_time}s" >> /tmp/gpu_parallel_test.log
            fi
        } &
    done
    
    wait
    local parallel_end=$(date +%s.%N)
    local parallel_total=$(echo "scale=3; $parallel_end - $parallel_start" | bc)
    
    if [ -f /tmp/gpu_parallel_test.log ]; then
        local completed=$(wc -l < /tmp/gpu_parallel_test.log)
        local avg_parallel=$(awk '{sum+=$2; count++} END {print sum/count}' /tmp/gpu_parallel_test.log)
        success "–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: $completed/3"
        success "–û–±—â–µ–µ –≤—Ä–µ–º—è: ${parallel_total}s"
        success "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—Ä–æ—Å: ${avg_parallel}s"
        rm -f /tmp/gpu_parallel_test.log
    fi
    
    echo ""
}

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã
monitor_gpu_usage() {
    section "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU"
    
    # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    log "–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU –Ω–∞ 30 —Å–µ–∫—É–Ω–¥..."
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –ª–æ–≥–æ–≤
    local monitor_log="/tmp/gpu_monitor.log"
    > "$monitor_log"
    
    # –§–æ–Ω–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    {
        for i in {1..30}; do
            local timestamp=$(date +%s)
            local gpu_util=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits)
            local mem_used=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
            local mem_total=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
            local temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
            local power=$(nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits)
            
            echo "$timestamp,$gpu_util,$mem_used,$mem_total,$temp,$power" >> "$monitor_log"
            sleep 1
        done
    } &
    
    local monitor_pid=$!
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
    log "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏..."
    for i in {1..5}; do
        curl -s -X POST http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d '{"model":"llama3.2:3b","prompt":"–¢–µ—Å—Ç –Ω–∞–≥—Ä—É–∑–∫–∏ GPU","stream":false}' > /dev/null &
    done
    
    wait
    kill $monitor_pid 2>/dev/null || true
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    if [ -f "$monitor_log" ]; then
        log "–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:"
        
        local max_util=$(awk -F, '{if($2>max) max=$2} END {print max}' "$monitor_log")
        local avg_util=$(awk -F, '{sum+=$2; count++} END {print sum/count}' "$monitor_log")
        local max_mem=$(awk -F, '{if($3>max) max=$3} END {print max}' "$monitor_log")
        local max_temp=$(awk -F, '{if($5>max) max=$5} END {print max}' "$monitor_log")
        local max_power=$(awk -F, '{if($6>max) max=$6} END {print max}' "$monitor_log")
        
        success "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ GPU: ${max_util}%"
        success "–°—Ä–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞ GPU: ${avg_util}%"
        success "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: ${max_mem} MB"
        success "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: ${max_temp}¬∞C"
        success "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: ${max_power}W"
        
        rm -f "$monitor_log"
    fi
    
    echo ""
}

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å CPU –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
compare_cpu_gpu_performance() {
    section "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU vs GPU"
    
    info "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ CPU (–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–µ—Å—Ç–æ–≤):"
    info "  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ CPU: ~2.5s"
    info "  –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: CPU-only"
    
    log "–¢–µ–∫—É—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å GPU:"
    local gpu_start=$(date +%s.%N)
    local gpu_response=$(curl -s -X POST http://localhost:11434/api/generate \
        -H "Content-Type: application/json" \
        -d '{"model":"llama3.2:3b","prompt":"–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏","stream":false}')
    local gpu_end=$(date +%s.%N)
    local gpu_time=$(echo "scale=3; $gpu_end - $gpu_start" | bc)
    
    if [[ "$gpu_response" == *"response"* ]]; then
        success "–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ GPU: ${gpu_time}s"
        
        # –†–∞—Å—á–µ—Ç —É—Å–∫–æ—Ä–µ–Ω–∏—è
        local speedup=$(echo "scale=2; 2.5 / $gpu_time" | bc)
        if (( $(echo "$speedup > 1" | bc -l) )); then
            success "–£—Å–∫–æ—Ä–µ–Ω–∏–µ: ${speedup}x –±—ã—Å—Ç—Ä–µ–µ CPU"
        elif (( $(echo "$speedup < 1" | bc -l) )); then
            warning "GPU –º–µ–¥–ª–µ–Ω–Ω–µ–µ CPU –≤ ${speedup}x —Ä–∞–∑"
        else
            info "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å GPU –∏ CPU —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞"
        fi
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤
        local tokens=$(echo "$gpu_response" | jq -r '.eval_count // 0')
        if [ "$tokens" -gt 0 ]; then
            local tokens_per_sec=$(echo "scale=1; $tokens / $gpu_time" | bc)
            success "–°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: ${tokens_per_sec} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫"
        fi
    else
        error "–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è GPU"
    fi
    
    echo ""
}

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ GPU
generate_gpu_report() {
    section "–û—Ç—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU"
    
    local score=0
    local max_score=5
    local issues=()
    local recommendations=()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
    if nvidia-smi &> /dev/null; then
        score=$((score + 1))
        success "GPU: –î–æ—Å—Ç—É–ø–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç"
    else
        issues+=("GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –≤ Ollama
    local ollama_gpu=$(docker-compose logs ollama 2>/dev/null | grep -i cuda | wc -l)
    if [ "$ollama_gpu" -gt 0 ]; then
        score=$((score + 1))
        success "Ollama: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GPU"
    else
        issues+=("Ollama –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU")
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ GPU
    local gpu_memory=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
    if [ "$gpu_memory" -gt 1000 ]; then
        score=$((score + 1))
        success "–ü–∞–º—è—Ç—å GPU: –ê–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (${gpu_memory} MB)"
    else
        warning "–ü–∞–º—è—Ç—å GPU: –ù–∏–∑–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (${gpu_memory} MB)"
        recommendations+=("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU –≤ Ollama")
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    local gpu_temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
    if [ "$gpu_temp" -lt 80 ]; then
        score=$((score + 1))
        success "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ GPU: –ù–æ—Ä–º–∞–ª—å–Ω–∞—è (${gpu_temp}¬∞C)"
    else
        warning "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ GPU: –í—ã—Å–æ–∫–∞—è (${gpu_temp}¬∞C)"
        recommendations+=("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ GPU")
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    local perf_test=$(curl -s -X POST http://localhost:11434/api/generate \
        -H "Content-Type: application/json" \
        -d '{"model":"llama3.2:3b","prompt":"test","stream":false}' | jq -r '.response' 2>/dev/null)
    
    if [[ "$perf_test" != "null" ]] && [[ -n "$perf_test" ]]; then
        score=$((score + 1))
        success "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: GPU –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç"
    else
        issues+=("–ü—Ä–æ–±–ª–µ–º—ã —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –Ω–∞ GPU")
    fi
    
    # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    local percentage=$((score * 100 / max_score))
    echo ""
    
    if [ "$percentage" -ge 90 ]; then
        success "–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê GPU: ${percentage}% - –û—Ç–ª–∏—á–Ω–æ"
    elif [ "$percentage" -ge 70 ]; then
        info "–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê GPU: ${percentage}% - –•–æ—Ä–æ—à–æ"
    elif [ "$percentage" -ge 50 ]; then
        warning "–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê GPU: ${percentage}% - –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
    else
        error "–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê GPU: ${percentage}% - –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è"
    fi
    
    # –ü—Ä–æ–±–ª–µ–º—ã
    if [ ${#issues[@]} -gt 0 ]; then
        echo ""
        error "–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:"
        for issue in "${issues[@]}"; do
            echo "  ‚Ä¢ $issue"
        done
    fi
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if [ ${#recommendations[@]} -gt 0 ]; then
        echo ""
        warning "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:"
        for rec in "${recommendations[@]}"; do
            echo "  ‚Ä¢ $rec"
        done
    fi
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    echo ""
    info "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ GPU:"
    echo "  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU"
    echo "  ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É GPU –ø—Ä–∏ –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–∫–∞—Ö"
    echo "  ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ CUDA –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
    echo "  ‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ª–∏–º–∏—Ç—ã –ø–∞–º—è—Ç–∏ GPU –≤ Docker Compose"
}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
main() {
    echo -e "${PURPLE}"
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë                    GPU Performance Test                     ‚ïë"
    echo "‚ïë              –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU            ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo -e "${NC}"
    
    check_gpu_availability
    check_gpu_in_docker
    test_generation_performance
    monitor_gpu_usage
    compare_cpu_gpu_performance
    generate_gpu_report
    
    echo ""
    echo -e "${GREEN}"
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë            –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU –∑–∞–≤–µ—Ä—à–µ–Ω–æ                       ‚ïë"
    echo "‚ïë         –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ gpu_performance.txt          ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo -e "${NC}"
}

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
main "$@" | tee gpu_performance.txt
