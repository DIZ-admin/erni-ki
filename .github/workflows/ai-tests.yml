# AI Function Tests using GitHub Models
# Tests AI capabilities using GPT-4o-mini via GitHub Models API
# Uses built-in GITHUB_TOKEN - no separate API key needed!
#
# NOTE: Tests may fail due to rate limits (free tier: 15 RPM)
# This workflow uses continue-on-error to avoid blocking PRs

name: AI Function Tests

on:
  push:
    branches: [main, develop]
    paths:
      - "conf/litellm/**"
      - "scripts/**/*.py"
      - "tests/ai/**"
      - ".github/workflows/ai-tests.yml"
  pull_request:
    branches: [main, develop]
    paths:
      - "conf/litellm/**"
      - "scripts/**/*.py"
      - "tests/ai/**"
      - ".github/workflows/ai-tests.yml"
  workflow_dispatch:

# Permissions for GitHub token
permissions:
  contents: read
  models: read # Enable GitHub Models API access

# Environment variables
env:
  GITHUB_MODELS_ENDPOINT: https://models.github.ai/inference
  GITHUB_MODELS_MODEL: openai/gpt-4o-mini

# Cancel previous runs on new push
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  ai-tests:
    name: AI Function Tests
    runs-on: ubuntu-latest
    # Increased timeout: 6 tests Ã— 5s delay + execution time
    timeout-minutes: 5
    # Allow failure due to rate limits on free tier (15 RPM)
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: requirements-dev.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run AI function tests
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          pytest tests/ai/ -v --tb=short

      - name: Create test summary
        if: always()
        run: |
          echo "## AI Function Tests Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Model**: ${{ env.GITHUB_MODELS_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Endpoint**: ${{ env.GITHUB_MODELS_ENDPOINT }}" >> $GITHUB_STEP_SUMMARY
