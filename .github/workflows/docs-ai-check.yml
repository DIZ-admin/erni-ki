# AI-powered documentation quality validation using GitHub Models
# Analyzes markdown files for completeness, readability, and consistency

name: Docs AI Quality Check

on:
  push:
    branches: [main, develop]
    paths:
      - "docs/**/*.md"
      - "scripts/docs/ai_content_validator.py"
      - ".github/workflows/docs-ai-check.yml"
  pull_request:
    branches: [main, develop]
    paths:
      - "docs/**/*.md"
      - "scripts/docs/ai_content_validator.py"
      - ".github/workflows/docs-ai-check.yml"
  workflow_dispatch:
    inputs:
      path:
        description: "Path to validate (default: docs/)"
        required: false
        default: "docs/"
      threshold:
        description: "Minimum quality score (0-100)"
        required: false
        default: "60"

permissions:
  contents: read
  models: read # Enable GitHub Models API access
  pull-requests: write # For PR comments

env:
  GITHUB_MODELS_ENDPOINT: https://models.github.ai/inference
  GITHUB_MODELS_MODEL: openai/gpt-4o-mini

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  docs-ai-check:
    name: AI Documentation Quality
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: requirements-dev.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai

      - name: Get changed docs files
        id: changed-files
        if: github.event_name == 'pull_request'
        uses: tj-actions/changed-files@c3a1bb2c992d77180ae65be6ae6c166cf40f857c # v45.0.3
        with:
          files: |
            docs/**/*.md

      - name: Run AI documentation check (PR - changed files only)
        if: github.event_name == 'pull_request' && steps.changed-files.outputs.any_changed == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          CHANGED_FILES: ${{ steps.changed-files.outputs.all_changed_files }}
          THRESHOLD: ${{ github.event.inputs.threshold || '60' }}
        run: |
          echo "Checking changed documentation files..."

          # Create results directory
          mkdir -p artifacts
          echo '{"results": [' > artifacts/results.json
          first=true

          # Check each changed file (handle files with spaces using newline separator)
          IFS=$'\n'
          for file in $CHANGED_FILES; do
            echo "Validating: $file"
            if [ "$first" = true ]; then
              first=false
            else
              echo ',' >> artifacts/results.json
            fi
            python scripts/docs/ai_content_validator.py "$file" --ci >> artifacts/results.json 2>&1 || echo '{"file": "'"$file"'", "score": 0, "error": true}' >> artifacts/results.json
          done
          unset IFS
          echo ']}' >> artifacts/results.json

          # Show summary
          echo "## Documentation Quality Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat artifacts/results.json >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No results generated" >> $GITHUB_STEP_SUMMARY

      - name: Run AI documentation check (full scan)
        if: github.event_name != 'pull_request' || steps.changed-files.outputs.any_changed != 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PATH_TO_CHECK: ${{ github.event.inputs.path || 'docs/' }}
          THRESHOLD: ${{ github.event.inputs.threshold || '60' }}
        run: |
          echo "Running full documentation scan on: $PATH_TO_CHECK"

          # Run with threshold check
          python scripts/docs/ai_content_validator.py "$PATH_TO_CHECK" \
            --ci \
            --threshold "$THRESHOLD" \
            --output artifacts/results.json

          # Create summary
          echo "## Documentation Quality Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Path:** $PATH_TO_CHECK" >> $GITHUB_STEP_SUMMARY
          echo "**Threshold:** $THRESHOLD" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Extract summary stats
          if [ -f artifacts/results.json ]; then
            python3 -c "
          import json
          with open('artifacts/results.json') as f:
              data = json.load(f)
          print(f\"**Files checked:** {data.get('total_files', 0)}\")
          print(f\"**Average score:** {data.get('average_score', 0):.1f}/100\")
          " >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload results artifact
        if: always()
        uses: actions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874 # v4
        with:
          name: docs-ai-check-results
          path: artifacts/
          retention-days: 7
          if-no-files-found: ignore

      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea # v7
        with:
          script: |
            const fs = require('fs');
            const COMMENT_MARKER = '<!-- docs-ai-check -->';
            let comment = `${COMMENT_MARKER}\n## Documentation Quality Check\n\n`;

            try {
              const results = JSON.parse(fs.readFileSync('artifacts/results.json', 'utf8'));
              const avgScore = results.average_score || 0;
              const threshold = ${{ github.event.inputs.threshold || 60 }};

              if (avgScore >= threshold) {
                const emoji = avgScore >= 80 ? '✅' : '⚠️';
                comment += `${emoji} Average Score: ${avgScore.toFixed(1)}/100\n\n`;
              } else {
                comment += `❌ Average Score: ${avgScore.toFixed(1)}/100 (below threshold: ${threshold})\n\n`;
              }

              // List files with issues
              const issues = (results.results || []).filter(r => r.score < 80);
              if (issues.length > 0) {
                comment += '### Files needing attention:\n\n';
                for (const r of issues.slice(0, 5)) {
                  comment += `- **${r.file}**: ${r.score}/100\n`;
                  for (const issue of (r.issues || []).slice(0, 3)) {
                    comment += `  - ${issue.message}\n`;
                  }
                }
              }
            } catch (e) {
              comment += 'Results not available. Check workflow logs for details.';
            }

            // Find existing comment to update (prevents duplicates)
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            const botComment = comments.find(c =>
              c.body && c.body.includes(COMMENT_MARKER)
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
